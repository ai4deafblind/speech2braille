# Speech2Braille Server Configuration
# Copy this file to .env and modify as needed

# =============================================================================
# ASR (Automatic Speech Recognition) Configuration
# =============================================================================

# Whisper model name (tiny, base, small, medium, large-v3)
S2B_ASR_MODEL_NAME=base

# Optional path to local GGML model file (overrides model_name if set)
# S2B_ASR_MODEL_PATH=/path/to/ggml-model.bin

# Number of threads for inference
S2B_ASR_N_THREADS=4

# Default language for transcription (required for whisper.cpp)
S2B_ASR_DEFAULT_LANGUAGE=en

# Non-speech suppression (reduces hallucinations on silence/noise)
# Note: suppress_non_speech_tokens is not exposed in pywhispercpp C bindings (v1.4.1)
S2B_ASR_SUPPRESS_BLANK=true

# Quality thresholds for filtering low-confidence output
S2B_ASR_ENTROPY_THOLD=2.4
S2B_ASR_LOGPROB_THOLD=-1.0
S2B_ASR_NO_SPEECH_THOLD=0.6

# Streaming optimization
S2B_ASR_TEMPERATURE=0.0
S2B_ASR_SPLIT_ON_WORD=true

# =============================================================================
# WebSocket Streaming Configuration
# =============================================================================

# Audio sample rate in Hz
S2B_WS_SAMPLE_RATE=16000

# Process audio every N seconds (chunk duration for real-time output)
S2B_WS_CHUNK_DURATION=3.0

# Maximum buffer duration before force processing (safety limit)
S2B_WS_BUFFER_LIMIT=30.0

# Minimum audio duration to process
S2B_WS_MIN_DURATION=0.5

# Context carryover for better continuity between chunks
S2B_WS_CONTEXT_WINDOW_SECONDS=1.0
S2B_WS_USE_CONTEXT_CARRYOVER=true

# =============================================================================
# Voice Activity Detection (VAD) Configuration
# =============================================================================

# Enable/disable VAD (when disabled, uses fixed-interval processing)
S2B_VAD_ENABLED=true

# VAD library to use (silero, webrtc)
S2B_VAD_LIBRARY=silero

# Speech probability threshold (0.0-1.0, higher = less sensitive)
S2B_VAD_THRESHOLD=0.5

# Minimum speech duration to consider valid (ms)
S2B_VAD_MIN_SPEECH_DURATION_MS=250

# Silence duration to mark speech end (ms, higher = longer wait before processing)
S2B_VAD_MIN_SILENCE_DURATION_MS=800

# Padding before speech start (ms)
S2B_VAD_SPEECH_PAD_MS=30

# Force processing after this duration (s, safety limit)
S2B_VAD_MAX_SPEECH_DURATION_S=30.0

# Sensitivity preset (sensitive, balanced, conservative)
S2B_VAD_SENSITIVITY_PRESET=balanced

# Audio sample rate (must match WebSocket config)
S2B_VAD_SAMPLE_RATE=16000

# Frame size for processing (16ms at 16kHz = 512 samples)
S2B_VAD_FRAME_SIZE_SAMPLES=512

# =============================================================================
# Braille Translation Configuration
# =============================================================================

# Default braille table (see /api/tables for available options)
S2B_BRAILLE_DEFAULT_TABLE=en-ueb-g2.ctb

# =============================================================================
# CORS Configuration
# =============================================================================

# Allowed origins (comma-separated, use * for all)
# S2B_CORS_ALLOW_ORIGINS=["http://localhost:5173","http://localhost:3000"]
S2B_CORS_ALLOW_ORIGINS=["*"]
S2B_CORS_ALLOW_CREDENTIALS=true
S2B_CORS_ALLOW_METHODS=["*"]
S2B_CORS_ALLOW_HEADERS=["*"]

# =============================================================================
# Application Metadata
# =============================================================================

S2B_APP_TITLE=Brailler API
S2B_APP_VERSION=0.0.1
